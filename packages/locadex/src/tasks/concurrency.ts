import { LocadexManager } from '../utils/locadexManager.js';
import { logger } from '../logging/logger.js';
import { exit } from '../utils/shutdown.js';

/**
 * Wraps a promise with a timeout mechanism
 */
async function withTimeout<T>(
  promise: Promise<T>,
  timeoutSec: number,
  timeoutMessage?: string
): Promise<T> {
  const timeoutPromise = new Promise<never>((_, reject) => {
    global.setTimeout(() => {
      reject(
        new Error(timeoutMessage || `Operation timed out after ${timeoutSec}s`)
      );
    }, timeoutSec * 1000);
  });

  return Promise.race([promise, timeoutPromise]);
}

/**
 * Retries an async operation with exponential backoff
 */
async function withRetry<T>(
  operation: () => Promise<T>,
  maxRetries: number = 1,
  baseDelayMs: number = 1000
): Promise<T> {
  let lastError: Error;

  for (let attempt = 0; attempt <= maxRetries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error as Error;

      if (attempt === maxRetries) {
        throw lastError;
      }

      const delay = baseDelayMs * Math.pow(2, attempt);
      logger.debugMessage(
        `Agent operation failed (attempt ${attempt + 1}/${maxRetries + 1}), retrying in ${delay}ms: ${error}`
      );
      await new Promise((resolve) => global.setTimeout(resolve, delay));
    }
  }

  throw lastError!;
}

/**
 * Interface for defining how to process tasks in parallel.
 * Separates task preparation (preProcess) from result handling (postProcess).
 *
 * @template TTask - The type of individual tasks being processed
 * @template TContext - The type of shared context/configuration
 */
export interface TaskProcessor<TTask, TContext> {
  /**
   * Prepares tasks for processing and generates the prompt for the AI agent.
   * Called before each batch is sent to an agent.
   *
   * @param tasks - Batch of tasks to process
   * @param context - Shared context containing configuration and state
   * @returns Promise that resolves to the prompt string for the AI agent
   */
  preProcess: (tasks: TTask[], context: TContext) => Promise<string>;

  /**
   * Handles the results after the AI agent completes processing.
   * Called after each batch is successfully processed.
   *
   * @param tasks - The batch of tasks that were processed
   * @param context - Shared context containing configuration and state
   * @param agentReport - The report/output generated by the AI agent
   */
  postProcess: (
    tasks: TTask[],
    context: TContext,
    agentReport: string
  ) => Promise<void>;
}

/**
 * Configuration options for parallel processing behavior.
 */
export interface ParallelProcessingOptions {
  /** Number of concurrent agents to run in parallel */
  concurrency: number;
  /** Number of tasks to process in each batch */
  batchSize: number;
}

/**
 * Executes tasks in parallel using a pool of agents with proper concurrency control.
 *
 * This is a generic parallel processing framework that handles:
 * - Task queue management with thread-safe access
 * - Agent pool creation and lifecycle management
 * - Error handling and abort signal propagation
 * - Proper cleanup and resource management
 *
 * @template TTask - The type of tasks to process (e.g., string, object, etc.)
 * @template TContext - The type of context passed to the processor functions
 *
 * @param taskQueue - Array of tasks to process. Will be consumed (mutated) during processing.
 * @param processor - Object implementing preProcess and postProcess methods for task handling
 * @param context - Context object passed to processor methods, containing shared state/config
 * @param options - Configuration for parallel processing (concurrency level, batch size)
 *
 * @throws {Error} If processing fails or is aborted
 *
 * @example
 * ```typescript
 * const processor: TaskProcessor<string, { config: Config }> = {
 *   preProcess: async (files, context) => generatePrompt(files, context.config),
 *   postProcess: async (files, context, report) => handleResults(files, report)
 * };
 *
 * await runParallelProcessing(
 *   ['file1.ts', 'file2.ts'],
 *   processor,
 *   { config: myConfig },
 *   { concurrency: 3, batchSize: 2 }
 * );
 * ```
 */
export async function runParallelProcessing<TTask, TContext>(
  taskQueue: TTask[],
  processor: TaskProcessor<TTask, TContext>,
  context: TContext,
  options: ParallelProcessingOptions,
  timeoutSecPerTask: number = 60,
  maxRetries: number = 1
): Promise<void> {
  const { concurrency, batchSize } = options;
  const manager = LocadexManager.getInstance();

  const agentAbortController = manager.getAgentAbortController();
  let firstError: Error | null = null;

  // Mutex for task queue access
  let taskQueueMutex = Promise.resolve();

  // Helper function to safely get tasks from queue
  const getNextTasks = async (batchSize: number): Promise<TTask[]> => {
    return new Promise((resolve) => {
      taskQueueMutex = taskQueueMutex.then(() => {
        const tasks = taskQueue.splice(0, batchSize);
        resolve(tasks);
      });
    });
  };

  const processTask = async (): Promise<void> => {
    while (taskQueue.length > 0 && !agentAbortController.signal.aborted) {
      // Check if we should abort early
      if (agentAbortController.signal.aborted) {
        return;
      }

      // Get an available agent atomically
      const agentInfo = await manager.getAvailableAgent();
      if (!agentInfo) {
        // No available agents, wait a bit (but check for abort)
        await new Promise((resolve) => {
          const timeout = global.setTimeout(resolve, 100);
          agentAbortController.signal.addEventListener('abort', () => {
            global.clearTimeout(timeout);
            resolve(undefined);
          });
        });
        continue;
      }

      const { id: agentId, agent, sessionId } = agentInfo;

      // Get the next batch of tasks (thread-safe)
      const tasks = await getNextTasks(batchSize);
      if (tasks.length === 0) {
        manager.markAgentFree(agentId);
        break;
      }

      logger.debugMessage(`Using agent ${agentId} for ${tasks.length} tasks.`);

      // Process tasks using the provided processor
      try {
        // Pre-process: generate prompt
        const prompt = await processor.preProcess(tasks, context);

        // dynamic timeout based on the number of tasks
        const dynamicTimeoutSec = timeoutSecPerTask * tasks.length;

        // Claude call with timeout and retry
        await withRetry(
          () =>
            withTimeout(
              agent.run(
                {
                  prompt,
                  sessionId,
                },
                {}
              ),
              dynamicTimeoutSec,
              `Agent operation timed out after ${dynamicTimeoutSec}s`
            ),
          maxRetries
        );

        const agentReport = agent.generateReport();
        manager.markAgentFree(agentId);

        // Post-process: handle reports, progress, etc.
        await processor.postProcess(tasks, context, agentReport);
      } catch (error) {
        // Check if this is an abort
        if (agentAbortController.signal.aborted) {
          return;
        }

        // Capture the first error and signal all other agents to abort
        if (!firstError) {
          firstError = new Error(
            `Error in claude parallel process (${agentId}): ${error}`
          );
          logger.debugMessage(firstError.message);
        }
        await exit(1); // Exit this agent's processing immediately
        return;
      }
    }
  };

  // Create agent pool
  manager.createAgentPool();

  // Start parallel processing
  const processingPromises = Array.from({ length: concurrency }, () =>
    processTask()
  );

  try {
    await Promise.all(processingPromises);
  } catch (error) {
    // Check if this is an abort
    if (agentAbortController.signal.aborted) {
      throw new Error('Processing aborted');
    }

    // This shouldn't happen since we handle errors within processTask
    logger.debugMessage(`Unexpected error in parallel processing: ${error}`);
    if (!firstError) {
      firstError = new Error(
        `Unexpected error in parallel processing: ${error}`
      );
    }
    throw firstError;
  }

  if (firstError) {
    throw firstError;
  }
}
